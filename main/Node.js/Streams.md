
Потоки в Node.js позволяют нам обрабатывать большие данные порционно, чанками. Тем самым не загружая полностью данные в оперативную память.

Выделяются 4 вида потоков:
- Writable
- Readable
- Duplex
- Transform

Все потоки, созданные API Node.js, работают исключительно со строками, объектами `Buffer` , `TypedArray` и `DataView` :

- `Strings` и `Buffers` являются наиболее распространенными типами, используемыми с потоками.
- `TypedArray` и `DataView` позволяет обрабатывать двоичные данные с типами вроде `Int32Array` или `Uint8Array`.

Однако реализациям потоков можно работать с другими типами значений JavaScript (за исключением `null`, который служит особой цели в потоках). 
Такие потоки считаются работающими в «**объектном режиме**».

#### Буферизация

Оба потока `Writable` и `Readable` будут хранить данные во внутреннем буфере.

Объем потенциально буферизованных данных зависит от `highWaterMark` параметра, переданного в конструктор потока. 
- Для обычных потоков `highWaterMark` параметр указывает общее количество байтов . 
- Для потоков, работающих в **объектном режиме**, `highWaterMark` указывает общее количество объектов.
- Для потоков, работающих со строками, `highWaterMark` указывает общее количество кодовых единиц UTF-16.


Данные буферизуются в `Readable` потоках, когда реализация вызывает `stream.push(chunk)`. Если потребитель потока не вызывает `stream.read()`, данные будут находиться во внутренней очереди до тех пор, пока не будут потреблены.

Как только общий размер внутреннего буфера чтения достигнет порогового значения, указанного параметром `highWaterMark`, поток временно прекратит чтение данных из базового ресурса до тех пор, пока текущие буферизованные данные не будут потреблены (то есть поток прекратит вызывать внутренний `readable._read()` метод, который используется для заполнения буфера чтения).

Данные буферизуются в `Writable` потоках, когда `writable.write(chunk)` метод вызывается повторно. Пока общий размер внутреннего буфера записи ниже порогового значения, установленного `highWaterMark`, вызовы `writable.write()` вернут `true`. Как только размер внутреннего буфера достигнет или превысит `highWaterMark`,  будет возвращен `false`.

Основная цель API `stream`, в частности `stream.pipe()` метода, заключается в ограничении буферизации данных до приемлемых уровней, чтобы источники и пункты назначения с разными скоростями не перегружали доступную память. (**backpressure** problem)

Эта `highWaterMark` опция является порогом, а не пределом: она определяет объем данных, которые поток буферизует, прежде чем перестанет запрашивать дополнительные данные. Она не налагает строгих ограничений на память в целом. Конкретные реализации потоков могут выбирать для наложения более строгих ограничений, но это необязательно.

Поскольку `Duplex` и `Transform` потоки являются и `Readable` и `Writable`, каждый из них поддерживает два отдельных внутренних буфера, используемых для чтения и записи, что позволяет каждой стороне работать независимо от другой, поддерживая при этом соответствующий и эффективный поток данных. Например, `net.Socket` экземпляры — это `Duplex` потоки, `Readable` сторона которых позволяет потреблять данные, полученные из сокета, и `Writable` сторона которых позволяет записывать данные в сокет. Поскольку данные могут записываться в сокет с более высокой или низкой скоростью, чем они принимаются, каждая сторона должна работать (и буферизировать) независимо от другой.

Механизм внутренней буферизации является внутренней деталью реализации и может быть изменен в любое время. Однако для некоторых расширенных реализаций внутренние буферы могут быть извлечены с помощью `writable.writableBuffer`или `readable.readableBuffer`. Использование этих недокументированных свойств не рекомендуется.
##### *Backpressure*
Предположим, мы читаем данные из быстрого источника и записываем их в медленный.
Из-за этого, может возникнуть проблема backpressure, то есть поток, который вычитывает данные, уже готов их отдать в следующий поток, но этот следующий поток уже переполнил свой буффер и не может пока принимать данные.

Поэтому можно использовать метод `.pause()` на читающем потоке, а когда записывающий поток опустошит свой буффер (кинет событие `drain`), возобновить его:

```js
    source.on('data', (chunk) => {
        // Если Writable Stream переполнен, приостанавливаем Readable Stream
        if (!destination.write(chunk)) {
            source.pause();
        }
    });

    // Когда Writable Stream освобождается, возобновляем Readable Stream
    destination.on('drain', () => {
        source.resume();
    });
```





### Writable Streams
Примеры :
- HTTP requests, on the client
- HTTP responses, on the server
- fs write streams
- zlib streams
- crypto streams
- TCP sockets
- child process stdin
- process.stdout, process.stderr
Некоторые из этих примеров на самом деле являются `Duplex` потоками, реализующими `Writable` интерфейс.

Реализует интерфейсы
#### `stream.Writable`:

##### **`writable.write(chunk, encoding?, callback?)`**  
- `chunk`: `string | Buffer | TypedArray | DataView | any`  
	Необязательные данные для записи. Для потоков, не работающих в объектном режиме, `chunk` должны быть `string | Buffer | TypedArray | DataView` . 
	Для потоков объектного режима `chunk` может быть любым значением JavaScript, кроме `null`.
- `encoding`: `string | null` Кодировка, если `chunk` это строка. По умолчанию: `'utf8'`
-  `callback`: `Function` коллбек, который вызвается, когда чанк записан.
- return: `boolean` - Если чанк попал во внутренний буффер, возвращает `true`. Возвращает `false`, если внутренний буффер переполнен. В этом случае нужно дождаться ивента `drain`, чтобы продолжить запись

Метод `writable.write()` записывает некоторые данные в поток и вызывает предоставленный `callback` после полной обработки данных. Если возникает ошибка, `callback` будет вызван с ошибкой в ​​качестве первого аргумента. `callback` Вызывается асинхронно и перед тем, как `error` будет выдан.

Возвращаемое значение — `true` если внутренний буфер меньше настроенного `highWaterMark` при создании потока после допуска `chunk`. Если `false` возвращается, дальнейшие попытки записи данных в поток должны прекратиться до тех пор, пока  не будет отправлено событие `'drain'`.

##### **`writable.end(chunk, encoding?, callback?)`**  
Вызов `writable.end()` метода сигнализирует о том, что больше данные не будут записаны в `Writable`. Необязательные аргументы `chunk` и `encoding` позволяют записать еще один последний дополнительный фрагмент данных непосредственно перед закрытием потока.

Вызов `stream.write()` метода после вызова `stream.end()` приведет к ошибке.

##### **`writable.cork()`**  
Метод `writable.cork()` заставляет все записанные данные буферизироваться в памяти. Буферизованные данные будут сброшены при вызове методов `stream.uncork()` или `stream.end()`

Основное назначение `writable.cork()` — приспособиться к ситуации, когда несколько небольших фрагментов записываются в поток в быстрой последовательности. Вместо того, чтобы немедленно пересылать их в целевой пункт назначения, `writable.cork()` буферизует все фрагменты до тех пор, пока `writable.uncork()` не будет вызван , который передаст их все в `writable._writev()`, если он присутствует. 
Это предотвращает ситуацию блокировки начала очереди, когда данные буферизуются в ожидании обработки первого небольшого фрагмента. Однако использование `writable.cork()` без реализации `writable._writev()` может оказать неблагоприятное влияние на пропускную способность.

Этот метод полезен, когда нужно записывать несколько чанков данных сразу, минимизируя системные вызовы.

```js
writable.cork(); // Начинаем буферизацию 
writable.write('Первая часть '); 
writable.write('второй части.'); 
writable.uncork(); // Все накопленные данные записываются разом
```

##### **`writable.uncork()`**  
Метод `writable.uncork()` записывает все данные, буферизованные с момента `stream.cork()` вызова.

Если `writable.cork()` метод вызывается в потоке несколько раз, `writable.uncork()` для очистки буферизованных данных необходимо выполнить такое же количество вызовов.

```js
stream.cork();
stream.write('some ');
stream.cork();
stream.write('data ');
process.nextTick(() => {
  stream.uncork();
  // The data will not be flushed until uncork() is called a second time.
  stream.uncork();
}); 
```
Рекомендуется вызывать `uncork()` внутри `process.nextTick()`, чтобы гарантировать сброс буферизованных данных после завершения текущего блока кода. Это помогает избежать неожиданных задержек в обработке потока.

```js
writable.cork();
writable.write('Часть 1 ');
writable.write('Часть 2');
writable.uncork(); // Буфер сбрасывается прямо здесь

writable.write('Часть 3'); // Это отдельный вызов write()
```

```
Записано: Часть 1 Часть 2
Записано: Часть 3
```

Хотя Часть 1 и Часть 2 объединились, Часть 3 записалась отдельно.

```js
writable.cork();
writable.write('Часть 1 ');
writable.write('Часть 2');

process.nextTick(() => {
  writable.uncork(); // Теперь uncork вызывается в следующем цикле событий
});

writable.write('Часть 3');
```

```
Записано: Часть 1 Часть 2 Часть 3
```

Теперь весь буфер накопился и был записан разом.

`writable.writableCorked`
Возвращает чиссло, сколько необходимо раз `writable.uncork()` вызвать, чтобы полностью открыть поток.

##### **`writable.destroy(err?)`**  
Уничтожить поток. При желании сгенерировать `'error'` событие и сгенерировать `'close'` событие (если не `emitClose` установлено значение false).

После этого вызова записываемый поток завершается, и последующие вызовы `write()` или `end()` приведут к `ERR_STREAM_DESTROYED` ошибке. Это разрушительный и немедленный способ уничтожить поток. Предыдущие вызовы `write()` могли не быть слиты и могут вызвать `ERR_STREAM_DESTROYED` ошибку. Используйте `end()` вместо `destroy()`, если данные должны быть записаны перед закрытием, или дождитесь `'drain'` события перед уничтожением потока.

и тд. (https://nodejs.org/api/stream.html#writable-streams)

#### События:

##### `'close'`
Событие `'close'` выдается, когда поток и любой из его базовых ресурсов (например, файловый дескриптор) были закрыты. Событие указывает, что больше не будет выдаваться никаких событий, и никаких дальнейших вычислений не будет.

Поток `Writable` всегда будет генерировать `'close'` событие, если он создан с `emitClose` опцией.

##### `'drain'`
Если вызов `stream.write(chunk)` возвращает `false`, `'drain'` событие будет сгенерировано, когда будет уместно возобновить запись данных в поток.

##### `'error'`
Событие `'error'` выдается, если произошла ошибка при записи или передаче данных. Коллбек слушателя получит в Error аргумент

Поток закрывается при возникновении события `'error'`, если только при создании потока параметр `autoDestroy` не был установлен в значение `false`.

После `'error'` не должно быть никаких других событий, кроме `'close'` (включая события `'error'`).

##### `'finish'`
Событие `'finish'` генерируется после вызова метода `stream.end()` и записи всех данных в целевую систему.

##### `'pipe'`
Событие `'pipe'` генерируется, когда метод `stream.pipe()` вызывается для читаемого потока, добавляя этот записываемый поток в свой набор назначений.

```
const writer = getWritableStreamSomehow();
const reader = getReadableStreamSomehow();
writer.on('pipe', (src) => {
  console.log('Something is piping into the writer.');
  assert.equal(src, reader);
});
reader.pipe(writer);
```

##### `'unpipe'`
Событие `'unpipe'` генерируется, когда метод `stream.unpipe()` вызывается для потока `Readable`, удаляя этот `Writable` из набора назначений.

```js
const writer = getWritableStreamSomehow();
const reader = getReadableStreamSomehow();
writer.on('unpipe', (src) => {
  console.log('Something has stopped piping into the writer.');
  assert.equal(src, reader);
});
reader.pipe(writer);
reader.unpipe(writer); 
```



### Readable streams

Примеры:

- HTTP responses, on the client
- HTTP requests, on the server
- fs read streams
- zlib streams
- crypto streams
- TCP sockets
- child process stdout and stderr
- process.stdin

#### Режимы чтения
Readable стримы могут работать в двух режимах **flowing** и **paused**
- **flowing**: данный читаются из источника автоматически и передаются в приложение используя интерфейс EventEmitter.
- **paused**: Для чтения фрагментов данных из потока необходимо явно вызывать метод stream.read().

Чтобы перейти в flowing-режим:
- Добавить слушателя `data`
- Вызвать `resume()`
- Подключить поток к Writable (pipe())

Чтобы вернуться в **paused**-режим:
- Вызвать `pause()`
- У всех стримом в `pipe` вызвать метод `unpipe`

Важно помнить, что `Readable` **не будет генерировать данные**, пока не будет предоставлен механизм для потребления или игнорирования этих данных. Если механизм потребления отключен или удален, Readable попытается прекратить генерировать данные.

Если Readable переключается в режим потока и нет потребителей, доступных для обработки данных, эти данные будут потеряны. Это может произойти, например, когда метод `readable.resume()` вызывается без прослушивателя, прикрепленного к событию 'data', или когда обработчик событий 'data' удаляется из потока.

Добавление обработчика событий `'readable'` автоматически останавливает поток, и данные должны быть потреблены через `readable.read()`. Если обработчик событий `'readable'` удален, поток снова начнет течь, если есть обработчик событий `'data'`.

В частности, в любой момент времени каждый Readable находится в одном из трех возможных состояний:

- `readable.readableFlowing === null`
- `readable.readableFlowing === false`
- `readable.readableFlowing === true`

Когда `readable.readableFlowing` равен `null`, механизм потребления данных потока не предоставляется. Поэтому поток не будет генерировать данные. В этом состоянии подписка прослушивателя для события `'data'`, вызов метода `readable.pipe()` или вызов метода `readable.resume()` переключит `readable.readableFlowing` в значение `true`, заставив `Readable` начать активно испускать события по мере генерации данных.

Вызов `readable.pause()`, `readable.unpipe()` или в случае backpressure приведет к тому, что `readable.readableFlowing` будет установлен как `false`, временно останавливая поток событий, но не останавливая генерацию данных. В этом состоянии подписка слушателя для события `'data'` не переключит `readable.readableFlowing` в true.

```js
const { PassThrough, Writable } = require('node:stream');
const pass = new PassThrough();
const writable = new Writable();

pass.pipe(writable);
pass.unpipe(writable);
// readableFlowing is now false.

pass.on('data', (chunk) => { console.log(chunk.toString()); });
// readableFlowing is still false.
pass.write('ok');  // Will not emit 'data'.
pass.resume();     // Must be called to make stream emit 'data'.
// readableFlowing is now true. 
```

Пока `readable.readableFlowing` имеет значение `false`, данные могут накапливаться во внутреннем буфере потока.

API потока Readable развивалось в нескольких версиях Node.js и предоставляет несколько методов получения потоковых данных. 
В целом, разработчикам следует выбирать один из методов получения данных и никогда не следует использовать несколько методов для получения данных из одного потока. В частности, использование комбинации  `on('data')`, `on('readable')`, `pipe()` или `async iterators` может привести к неочевидному поведению.

Реализует интерфейсы
#### `stream.Readable`:
##### **`readable.read(size?)`**  
- `size` : `number` Необязательный аргумент для указания объема данных для считывания.
- return `string | Buffer | null | any`

Метод `readable.read()` считывает данные из внутреннего буфера и возвращает их.

Если данные для чтения недоступны, возвращается `null`. 

По умолчанию данные возвращаются как объект `Buffer`, если только кодировка не была указана с помощью метода `readable.setEncoding()` или поток не работает в объектном режиме.

Необязательный аргумент `size` указывает определенное количество байтов для чтения. Если `size` байтов недоступно для чтения, будет возвращено значение `null`, если только поток не закончился, в этом случае будут возвращены все данные, оставшиеся во внутреннем буфере.

Если аргумент `size` не указан, будут возвращены все данные, содержащиеся во внутреннем буфере.

Аргумент size должен быть меньше или равен 1 GiB.

Метод `readable.read()` следует вызывать только для потоков Readable, работающих в `paused` режиме. 

В режиме `flowing` readable.read() вызывается автоматически до тех пор, пока внутренний буфер не будет полностью опустошен.


```js
const readable = getReadableStreamSomehow();

// 'readable' may be triggered multiple times as data is buffered in
readable.on('readable', () => {
  let chunk;
  console.log('Stream is readable (new data received in buffer)');
  // Use a loop to make sure we read all currently available data
  while (null !== (chunk = readable.read())) {
    console.log(`Read ${chunk.length} bytes of data...`);
  }
});

// 'end' will be triggered once when there is no more data available
readable.on('end', () => {
  console.log('Reached end of stream.');
});
```

Каждый вызов `readable.read()` возвращает фрагмент данных или `null`, что означает, что в данный момент больше нет данных для чтения. 

Эти фрагменты не объединяются автоматически. Поскольку один вызов `read()` не возвращает все данные (??????? выше же написано, что вовращает, если не передать `size`), может потребоваться использование цикла `while` для непрерывного чтения фрагментов до тех пор, пока не будут извлечены все данные. 

При чтении большого файла `.read()` может временно возвращать `null`, что означает, что он израсходовал все буферизованное содержимое, но могут быть еще данные, которые еще предстоит буферизовать. 

В таких случаях новое событие `'readable'` генерируется, как только в буфере появляется больше данных, а событие `'end'` означает завершение передачи данных.

Поток Readable в объектном режиме всегда будет возвращать один элемент из вызова `readable.read(size)`, независимо от значения аргумента `size`.

##### `readable.readable`

Имеет значение true, если безопасно вызывать `readable.read()`, что означает, что поток не был уничтожен или не выдал `'error'` или `'end'`.


##### `readable.pause()`
Метод `readable.pause()` заставит поток в режиме потока прекратить испускать события `'data'`, выключая режим потока. Любые данные, которые станут доступны, останутся во внутреннем буфере.

Метод `readable.pause()` не действует, если имеется прослушиватель событий `'readable'`.

##### `readable.resume()`

Метод `readable.resume()` заставляет явно приостановленный поток Readable возобновлять отправку событий `'data'`, переключая поток в режим потока.

Метод `readable.resume()` можно использовать для полного использования данных из потока без фактической обработки этих данных.

```
getReadableStreamSomehow()
  .resume()
  .on('end', () => {
    console.log('Reached the end, but did not read anything.');
  }); 
```

Метод `readable.resume()` не действует, если имеется хендлер событий `'readable'`.

##### `readable.unpipe(destination?)`
- `destination`: `stream.Writable` - Необязательный определенный поток для отсоединения

Метод `readable.unpipe()` отсоединяет записываемый поток, ранее присоединенный с помощью метода `stream.pipe()`.

Если `destination` не указан, то все каналы отсоединяются. 
Если `destination` указан, но для него не настроен канал, то метод ничего не делает.

```js
const fs = require('node:fs');
const readable = getReadableStreamSomehow();
const writable = fs.createWriteStream('file.txt');
// All the data from readable goes into 'file.txt',
// but only for the first second.
readable.pipe(writable);
setTimeout(() => {
  console.log('Stop writing to file.txt.');
  readable.unpipe(writable);
  console.log('Manually close the file stream.');
  writable.end();
}, 1000); 
```


#####  `readable.push(chunk, encoding?)`
- `chunk`: `Buffer | TypedArray | DataView | string | null | any`. Часть данных для переноса в очередь чтения. Для потоков, не работающих в объектном режиме, `chunk` должен быть `Buffer | TypedArray | DataView | string | null`. Для потоков объектного режима `chunk` может быть любым значением JavaScript.
- `encoding`: `string` Кодировка фрагментов строк. Должна быть допустимая кодировка буфера, например 'utf8' или 'ascii'.

Когда chunk — это `Buffer | TypedArray | DataView | string`, фрагмент данных будет добавлен во внутреннюю очередь для consumers потоков. 
Передача `chunk` как `null` сигнализирует о конце потока (EOF), после чего больше нельзя записывать данные.

Когда Readable работает в режиме паузы, данные, добавленные с помощью `readable.push()`, можно считать, вызвав метод `readable.read()` при возникновении события `'readable'`.

Когда Readable работает в потоковом режиме, данные, добавленные с помощью `'readable.push()'`, будут доставлены путем отправки события `'data'`.

Метод `readable.push()` используется для помещения содержимого во внутренний буфер. Он может управляться методом `readable._read()`.

Для потоков, не работающих в объектном режиме, если параметр `chunk` `readable.push()` не определен, он будет рассматриваться как пустая строка или буфер

##### `readable._read(size)`
Эта функция НЕ ДОЛЖНА вызываться кодом приложения напрямую. Она должна быть реализована дочерними классами и вызываться только внутренними методами класса Readable.

Все реализации потока Readable должны обеспечивать реализацию метода `readable._read()` для извлечения данных из базового ресурса.

При вызове `readable._read()`, если данные доступны из ресурса, реализация должна начать помещать эти данные в очередь чтения с помощью метода `this.push(dataChunk)`. `_read()` будет вызываться снова после каждого вызова `this.push(dataChunk)`, как только поток будет готов принять больше данных. `_read()` может продолжать чтение из ресурса и помещать данные в очередь до тех пор, пока `readable.push()` не вернет `false`. Только когда `_read()` вызывается снова после остановки, он должен возобновить помещение дополнительных данных в очередь.



##### `readable.unshift(chunk, encoding?)`
- `chunk`: `Buffer | TypedArray | DataView | string | null | any`. Часть данных для переноса в очередь чтения. Для потоков, не работающих в объектном режиме, `chunk` должен быть `Buffer | TypedArray | DataView | string | null`. Для потоков объектного режима `chunk` может быть любым значением JavaScript.
- `encoding`: `string` Кодировка фрагментов строк. Должна быть допустимая кодировка буфера, например 'utf8' или 'ascii'.

Передача `chunk` как `null` сигнализирует о конце потока (EOF) и ведет себя так же, как `readable.push(null)`, после чего больше данные не могут быть записаны. 
Сигнал EOF помещается в конец буфера, и любые буферизованные данные все равно будут сброшены.

Метод `readable.unshift()` возвращает часть данных обратно во внутренний буфер. Это полезно в определенных ситуациях, когда поток потребляется кодом, которому нужно «отменить потребление» некоторого количества данных, которые он оптимистично вытащил из источника, чтобы данные можно было передать какой-то другой стороне.

Метод `stream.unshift(chunk)` не может быть вызван после срабатывания события `end`, иначе возникнет ошибка времени выполнения.


и тд (https://nodejs.org/api/stream.html#readable-streams)

#### События:

##### `'data'`
Событие `'data'` генерируется всякий раз, когда поток передает владение фрагментом данных потребителю. Это может произойти всякий раз, когда поток переключается в режим потока путем вызова `readable.pipe()`, `readable.resume()` или путем подписки слушателя к событию `'data'`. Событие `'data'` также будет генерироваться всякий раз, когда вызывается метод `readable.read()` и фрагмент данных доступен для возврата.

Подписка прослушивателя событий `'data'` к потоку, который не был явно приостановлен, переключит поток в режим потока. Затем данные будут переданы, как только они станут доступны.

##### `'end'`
Событие `'end'` генерируется, когда из потока больше нет данных для потребления.

Событие `'end'` не будет отправлено, пока данные не будут полностью потреблены. Этого можно добиться, переключив поток в режим потока или вызвав stream.read() несколько раз, пока все данные не будут потреблены.

```js
const readable = getReadableStreamSomehow();
readable.on('data', (chunk) => {
  console.log(`Received ${chunk.length} bytes of data.`);
});
readable.on('end', () => {
  console.log('There will be no more data.');
});
```


##### `'pause'`
Событие `'pause'` генерируется, когда вызывается `stream.pause()` и `readableFlowing` не равен false.


##### `'readable'`
Событие `'readable'` генерируется, когда есть данные, доступные для чтения из потока, вплоть до `state.highWaterMark`. 
Фактически, оно указывает на то, что в буфере потока есть новая информация. Если в этом буфере есть данные, можно вызвать `stream.read()` для их извлечения. Кроме того, событие `'readable'` может также генерироваться при достижении конца потока.

Если достигнут конец потока, вызов `stream.read()` вернет `null` и вызовет событие `'end'`

В некоторых случаях подписка к событию `'readable'` приведет к считыванию некоторого объема данных во внутренний буфер.

В целом, механизмы событий readable.pipe() и 'data' проще понять, чем событие 'readable'. Однако обработка 'readable' может привести к увеличению пропускной способности.

Если одновременно используются и `'readable'`, и `'data'`, `'readable'` имеет приоритет в управлении потоком, т. е. `'data'` будет отправлено только при вызове `stream.read()`. Свойство `readableFlowing` станет `false`. 
Если есть прослушиватели `'data'`, когда `'readable'` удален, поток начнет течь, т. е. события `'data'` будут отправлены без вызова `.resume()`.

```js
const readable = getReadableStreamSomehow();
readable.on('readable', function() {
  // There is some data to read now.
  let data;

  while ((data = this.read()) !== null) {
    console.log(data);
  }
});
```

##### `'resume'`
Событие `'resume'` генерируется, когда вызывается `stream.resume()`, а `readableFlowing` не равен true.
